## Three asymtotic notations 
-  θ (Theta)
-- represents highest order terms 
<br>
```
eg θ(N^2) 
Anything which has has quadratic order
it can be 100n^2+1, 999n^2+n+1, 
it does not cover n + 1, 2n etc
```
-  O (Big Oh)
-- Represents all from higher order to lower order terms 
```
eg O(N^2) 
Anything which has has quadratic order
it can be 100n^2+1, 999n^2+n+1, n + 1, 2n, 1000
```

- Ω (Omega)
-- Represents value which have same or higher order of growth <br>
-- includes values represented by θ (Theta) notation
```
eg O(N^2) 
Anything which is equal or greater than quadratic order
it can be n^3+3n+1, 999n^2+n+1
The foll is not included : n + 1, 2n, 1000
```

<hr>

## Best case, average case, worst case of an algorithm

We are given an array arr, and an element x, we need to find if element x is present in given array or not
<br>
Below is code for linear search

```
bool search(int arr[], int n, int x)
{
    for(int i = 0; i < n; i++)
        if(arr[i] == x)
            return true;
    return false;
}
```
Best case -  when element is present at first index <br>
Worst case - when element is present at last index or it is not present in the array <br>
Average case - Consider all possible inputs, for every possible input we need to find how much time does the algo takes and take average i.e 

```
average = sum of time of all possible cases/ total no of cases 
```

Assuming all permutations of array are equally likely, 
compute time taken by every permutation divided by n!(n-factorial), n is no of elements in input array will be our answer 

```
Time complexity of above algo = O(n), since Big-oh notations includes all cases from n, n-1....2,,1
```
 
### Q) find order of growth of the below code

```
1) for(int i = 0; i < n; i = i + c)
    printf("I am Shyren");

Ans: loop runs n/c times, c is any real number
θ(n) - theta since the loop always runs n times

2) for(int i = n; i>0; i = i - c)
    printf("Algos are awesome");

Ans: loop runs n/c times, c is any real number
θ(n) - theta since the loop always runs n times

3) for(int i = 1; i < n; i = i * c)
    printf("I am Shyren");

Ans: runs for i = 1, c, c^2...c^k (assuming it runs some k times)

c^k < n
k < log n to the base c, 
which can be approximated to
k < log n 


4) for(int i = n; i>0; i = i / c)
    printf("Algos are awesome");

Ans: runs for i = n, n/c, n/c^2...n/c^k
n/c^k > 1
n > c^k
log n > k log c
log n > k (no log c, since it can be approximated) 
Final ans: O(log n)

5) for(int i = 2; i < n; i = pow(i, c))
    printf("Algos are awesome");

Ans: runs for i = 2, 2^c, (2^c)^c... 
                = 2^1 , 2^c, 2^c^2, 2^c^3....2^c^k

i.e; 2^c^k < n 
2^c^k < 2(logn to base 2)
c^k < log n (base 2 doesn't matter, since it's a constant)
k log c < log(log n) 
k < log (log n)

Final ans: O(log(log n))

6)  void fun(int arr[], int n)
    {
        if(n % 10 == 0)
            return 0;
        int sum = 0;
        for(int i = 0; i < n; i++)
            sum += arr[i];
        return sum; 
    }   

Ans : O(n) 
we can't say θ(n) since when n is divisible by 10, it takes constant time 

7)  void fun(int n, int m)
    {
        for(int i = 0; i < n; i++)
            printf("Hello");
        for(int i = 0; i < m; i++)
            printf("World");
    }

Ans: O(m+n) 
first loop runs for n times and second loop runs for m times 

8)  void fun(int n)
    {
        for(int i = 0; i < n; i++)
            for(int j = i; j < n; j++)
                print("Algo op");
    }

Ans: 
outer loop runs n times
inner loop runs from i to n-1
n + n-1 + n-2 +....+ 1
= n*(n+1)/2
= n^2/2 + n/2
= O(n^2)
= θ(n^2) since for any value of n, it's going to run n^2 times 


```

## Flaws of aysmtotic notations 
- talks about only order of growth
- does not talk about constants, or the exact time taken by program 
- does not consider other factors 
eg: quicksort algo has time complexity O(n^2) but still works better than merge sort which is O(nlog n) becuase it's more architecture friendly algo, more cache friendly 